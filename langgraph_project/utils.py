from typing import Any, List, Optional, Dict

import pandas as pd

from langchain.agents import AgentExecutor, ZeroShotAgent
from langchain.chains import LLMChain
from langchain_core.callbacks import BaseCallbackManager
from langchain_core.language_models import BaseLLM

from langchain_experimental.tools import PythonAstREPLTool

from prompts import pre_subfixes


# CUSTOM VERSION
class CustomAgentExecutor(AgentExecutor):
    """
    Custom AgentExecutor that includes a method to generate and refine insights.
    """

    def run_with_refinement(self, input, insight, process_steps, chat_history: Optional) -> str:
        """
        Generates an initial insight based on the provided input and then refines it using
        additional steps and context for a more actionable and detailed output.

        Args:
            input (str): The main question or prompt for generating insights.
            insight (str): An optional initial insight to refine further. If not provided,
                a new insight will be generated based on the input.
            process_steps (str): Additional information or intermediate steps that can be used
                to enhance or refine the insight, adding context or granularity as needed.
            chat_history (Optional): A record of previous interactions or exchanges, used to maintain
                continuity in the conversation and refine insights based on prior context.

        Returns:
            str: The refined insight generated by the function, incorporating the input, any initial
            insight, intermediate steps, and chat history for a thorough and actionable response.
        """
        # Step 1: Generate the initial insight
        # initial_response = self({"input": input, "insight": insight, "chat_history": chat_history})
        initial_response = self({"input": input,
                                 "insight": insight,
                                 "process_steps": process_steps,
                                 "chat_history": chat_history})

        return initial_response["output"]


def create_pandas_dataframe_agent_custom_experimental(
        llm: BaseLLM,
        dfs: Any,  # Dict[str, pd.DataFrame],
        prefix=pre_subfixes.PREFIX_PANDAS,
        suffix=pre_subfixes.SUFFIX_PANDAS,
        memory: Any = None,
        callback_manager: Optional[BaseCallbackManager] = None,
        input_variables: Optional[List[str]] = None,
        verbose: bool = False,
        return_intermediate_steps: bool = False,
        max_iterations: Optional[int] = 20,
        max_execution_time: Optional[float] = None,
        early_stopping_method: str = "force",
        **kwargs: Any,
) -> CustomAgentExecutor:
    """
    Constructs a custom agent to analyze multiple pandas DataFrames (`dfs`) using a language model,
    generating data-driven insights for strategic decision-making, such as negotiation support.

    Args:
        llm (BaseLLM): Language model used to generate insights.
        dfs (Dict[str, pd.DataFrame]): Dictionary of DataFrames with unique names for reference.
        prefix (str, optional): Prompt prefix to guide the agent's analysis.
        suffix (str, optional): Prompt suffix to refine agent responses.
        memory (Any, optional): Retains previous interactions for contextual analysis. Defaults to None.
        callback_manager (Optional[BaseCallbackManager], optional): Manages callbacks during execution.
        input_variables (Optional[List[str]], optional): Input variable names for the prompt.
        verbose (bool, optional): If True, enables detailed output. Defaults to False.
        return_intermediate_steps (bool, optional): If True, returns intermediate reasoning steps.
        max_iterations (Optional[int], optional): Maximum number of processing iterations. Defaults to 20.
        max_execution_time (Optional[float], optional): Maximum execution time in seconds. Defaults to None.
        early_stopping_method (str, optional): Method to stop execution early, defaults to "force".
        **kwargs (Any): Additional settings for the language model or tools.

    Returns:
        CustomAgentExecutor: An agent executor that processes natural language queries and
        generates structured, data-backed insights from the provided DataFrames.

    Raises:
        ValueError: If `dfs` is not a dictionary of DataFrames.

    Example:
        ```python
        dfs = {'sales_data': sales_df, 'customer_data': customer_df}
        agent = create_pandas_dataframe_agent_custom_test(llm=llm, dfs=dfs)
        result = agent.execute({"input": "Summarize recent sales trends."})
        ```
    """
    multi_dfs_flag = False

    if len(dfs) >= 2 and (isinstance(dfs, dict) or not isinstance(dfs, pd.DataFrame)):
        multi_dfs_flag = True

    # # Add each DataFrame to `locals` to make them accessible in the agent's scope
    if multi_dfs_flag:
        tools = [PythonAstREPLTool(locals={name: df for name, df in dfs.items()})]
        # Standard input variables for both initial insight and refinement
        input_vars = list(dfs.keys()) + ["input", "chat_history", "agent_scratchpad", "insight"]
    else:
        tools = [PythonAstREPLTool(locals={"df": dfs})]
        input_vars = ["df", "input", "chat_history", "agent_scratchpad"]

    # Update the prompt to handle multiple DataFrames by using `partial_prompt_content`
    prompt = ZeroShotAgent.create_prompt(
        tools,
        prefix=prefix,
        suffix=suffix,
        input_variables=input_vars
    )

    # Prepare a concatenated view of all DataFrames' heads for context
    if multi_dfs_flag:
        partial_prompt_content = "\n\n".join(f"{name}:\n{df.head()}" for name, df in dfs.items())
        partial_prompt = prompt.partial(dfs=partial_prompt_content)
    else:
        partial_prompt = prompt.partial(df=str(dfs.head()))

    llm_chain = LLMChain(
        llm=llm,
        prompt=partial_prompt,
        callback_manager=callback_manager,
    )

    tool_names = [tool.name for tool in tools]

    agent = ZeroShotAgent(
        llm_chain=llm_chain,
        allowed_tools=tool_names,
        callback_manager=callback_manager,
        **kwargs,
    )

    # Return a CustomAgentExecutor instead of the standard AgentExecutor
    return CustomAgentExecutor.from_agent_and_tools(
        agent=agent,
        tools=tools,
        verbose=verbose,
        return_intermediate_steps=return_intermediate_steps,
        max_iterations=max_iterations,
        max_execution_time=max_execution_time,
        early_stopping_method=early_stopping_method,
        callback_manager=callback_manager,
        memory=memory,
        handle_parsing_errors=True
    )


def create_pandas_dataframe_agent_custom(
        llm: BaseLLM,
        df: Any,
        prefix=pre_subfixes.PREFIX_PANDAS,
        memory: Any = None,
        callback_manager: Optional[BaseCallbackManager] = None,
        # input_variables: Optional[List[str]] = None,
        verbose: bool = False,
        return_intermediate_steps: bool = False,
        max_iterations: Optional[int] = 20,
        max_execution_time: Optional[float] = None,
        early_stopping_method: str = "force",
        **kwargs: Any,
) -> AgentExecutor:
    """
    Constructs a custom pandas agent that utilizes a language model to generate
    data-driven insights from a given pandas DataFrame (`df`). This agent is designed
    to respond to questions with specific, data-based answers tailored for Stora Enso’s
    negotiation objectives or other business strategies.

    Args:
        llm (BaseLLM): The language model to use for generating insights from data.
        df (Any): The pandas DataFrame containing data to be analyzed and queried.
        prefix (str, optional): Customizable prompt prefix to guide the agent's analysis.
            By default, it uses `custom_prompts.coder_bot.PREFIX_PANDAS`, which provides
            the agent with specific context and instructions for generating actionable insights.
        memory (Any, optional): Memory object to retain previous interactions. Defaults to None.
        callback_manager (Optional[BaseCallbackManager], optional): Manager for handling callbacks
            during processing, if applicable. Defaults to None.
        input_variables (Optional[List[str]], optional): List of input variable names to be
            used within the agent's prompt. Defaults to None, which sets the standard inputs
            ["df", "input", "agent_scratchpad"].
        verbose (bool, optional): If set to True, enables verbose output for debugging or
            detailed feedback. Defaults to False.
        return_intermediate_steps (bool, optional): If True, returns intermediate steps of
            the agent's reasoning, useful for detailed tracing of agent actions. Defaults to False.
        max_iterations (Optional[int], optional): Maximum number of iterations the agent can
            perform during execution, useful for controlling runtime. Defaults to 20.
        max_execution_time (Optional[float], optional): Maximum allowed time (in seconds) for
            the agent’s execution. If None, no time limit is enforced. Defaults to None.
        early_stopping_method (str, optional): Method to apply for early stopping during
            processing. Common values are "force" (halts after max iterations or time limit)
            or other custom methods. Defaults to "force".
        **kwargs (Any): Additional keyword arguments for fine-tuning the agent's behavior,
            such as configuration settings for the language model or specific tools.

    Returns:
        AgentExecutor: An initialized AgentExecutor object that can perform interactive
        data analysis on the DataFrame (`df`) using the provided language model. This
        executor is designed to process natural language queries and output structured,
        data-backed insights, which can then be used directly in negotiation or strategy contexts.

    Raises:
        ValueError: If `df` is not a pandas DataFrame, an error is raised to ensure
            compatibility with the agent’s data-handling expectations.
    """

    if not isinstance(df, pd.DataFrame):
        raise ValueError(f"Expected pandas object, got {type(df)}")

    # if input_variables is None:
    #     input_variables = ["df", "input", "agent_scratchpad"]

    tools = [PythonAstREPLTool(locals={"df": df})]

    # # ---------------------------------------
    # # Experimental
    # plot_displayer = initialize_tools(tools_names_to_use=['plot_displayer'], language_model=llm)
    # tools.extend(plot_displayer)
    # #print('tool_math', tool_math)
    # #print('tools', tools[1])  # TEST
    # # ---------------------------------------

    input_variables = ["df", "input", "chat_history", "agent_scratchpad"]

    prompt = ZeroShotAgent.create_prompt(
        tools,
        prefix=prefix,
        suffix=pre_subfixes.SUFFIX_PANDAS,
        input_variables=input_variables
    )

    partial_prompt = prompt.partial(df=str(df.head()))

    llm_chain = LLMChain(
        llm=llm,
        prompt=partial_prompt,
        callback_manager=callback_manager,
    )

    tool_names = [tool.name for tool in tools]

    agent = ZeroShotAgent(
        llm_chain=llm_chain,
        allowed_tools=tool_names,
        callback_manager=callback_manager,
        **kwargs,
    )

    return AgentExecutor.from_agent_and_tools(
        agent=agent,
        tools=tools,
        verbose=verbose,
        return_intermediate_steps=return_intermediate_steps,
        max_iterations=max_iterations,
        max_execution_time=max_execution_time,
        early_stopping_method=early_stopping_method,
        callback_manager=callback_manager,
        memory=memory,
        handle_parsing_errors=True  # TESTING
    )


class ConversationalAgents:
    def __init__(self):
        pass

    @staticmethod
    def chat_with_agent(agent, user_input):
        chat_history = list()

        # Append user input to chat_history and send it to the agent
        chat_history.append({"input": user_input})

        # Call the agent with `call` to capture multiple outputs
        response = agent.run(input=user_input, chat_history=chat_history)

        # Append agent's response to chat_history and display it
        chat_history.append({"response": response})

        return response

    @staticmethod
    def chat_with_agent_in_loop(agent):
        response = ''
        chat_history = list()
        print("Chatbot initialized. Type 'exit' to end the chat.")
        while True:
            # Accept user input
            user_input = input("You: ")

            # Exit the chat loop if the user types 'exit'
            if user_input.lower() == "exit":
                print("Ending chat.")
                break

            # Step 4: Append user input to chat_history and send it to the agent
            chat_history.append({"input": user_input})

            # -----------------------------
            # TEST
            # response = agent.run(input=user_input, chat_history=chat_history)
            # chat_history.append({"response": response})
            full_response = agent._call({"input": user_input, "chat_history": chat_history})
            intermediate_steps = full_response['intermediate_steps']
            print('intermediate_steps', intermediate_steps)
            # ----------------------------

            # Run the agent with the updated chat history
            # insight = agent1.run(input=user_input, chat_history=chat_history)
            # print('insight', insight)
            # # ----------------------------------------------
            # # BLOCK 1
            # # Call the agent with `call` to capture multiple outputs
            # full_response = agent1._call({"input": user_input, "chat_history": chat_history})
            #
            # # Extract the final answer and intermediate steps
            # insight = full_response['output']
            # intermediate_steps = full_response['intermediate_steps']
            #
            # print('Insight 1', insight)
            #
            # response = agent2.run_with_refinement(input=user_input,
            #                                       insight=insight,
            #                                       process_steps=intermediate_steps,
            #                                       chat_history=chat_history)
            # # ----------------------------------------------

            # ----------------------------------------------
            # BLOCK 2
            # Call the agent with `call` to capture multiple outputs
            # response = agent_custom.run(input=user_input, chat_history=chat_history)

            # Extract the final answer and intermediate steps
            # response = full_response['output']
            # ----------------------------------------------

            # Step 5: Append agent's response to chat_history and display it
            # chat_history.append({"response": response})

        return response

# --------
# APPENDIX
# --------

# from lang_models import BaseChain
# from langchain.prompts.prompt import PromptTemplate


# load_dotenv()
#
# os.getenv('GOOGLE_CSE_ID')
# os.getenv('GOOGLE_API_KEY')
#
#
# def get_custom_tool(func: Any, name: str, description: str) -> Tool:
#     """
#     Create a custom tool with the provided function, name, and description.
#
#     Args:
#         func (Any): The function to be associated with the tool.
#         name (str): The name of the tool.
#         description (str): The description of the tool.
#
#     Returns:
#         Tool: The custom tool object.
#     """
#     return Tool(
#         name=name,
#         func=func.run,
#         description=description
#     )
#
#
# def initialize_agent_executor(language_model: AzureChatOpenAI, tools: List[Tool], memory: Any = None,
#                               custom_template: Any = None) -> AgentExecutor:
#     """
#     Initialize the agent executor with the provided language model, tools, memory, and custom template.
#
#     Args:
#         language_model (AzureChatOpenAI): The language model to be used.
#         tools (List[Tool]): The list of tools to be used.
#         memory (Any, optional): The memory to be used. Defaults to None.
#         custom_template (Any, optional): The custom template to be used. Defaults to None.
#
#     Returns:
#         AgentExecutor: The initialized agent executor.
#     """
#     prompt = hub.pull("hwchase17/react")
#
#     if custom_template is not None:
#         prompt.template = custom_template
#
#     # TODO: IMPLEMENT DIFFERENT AGENTS
#     # llm_with_stop = language_model.bind(stop=["\nFinal Answer"])  # TEST
#     agent = create_react_agent(language_model, tools, prompt)
#     return AgentExecutor(agent=agent,
#                          tools=tools,
#                          verbose=True,  # True
#                          handle_parsing_errors='Return Final Answer',
#                          # "Check your output and make sure it conforms, use the Action/Action Input syntax",
#                          # True,
#                          memory=memory,
#                          # max_execution_time=30,
#                          max_iterations=15,
#                          early_stopping_method='generate'  #
#                          )
#
#
# # TODO MEMORY ADDED , CHECK WITH OTHER FUNCTIONS
# def initialize_llms_chain_as_tools(llm: Any, answer_prompt_template, memory=None) -> ConversationChain:
#     """
#     Load the tool functions using the provided language model.
#
#     Args:
#         llm (Any): The language model to be used.
#
#     Returns:
#         ConversationChain: The initialized conversation chain.
#     """
#
#     answer_prompt = PromptTemplate(input_variables=["history", "input"],
#                                    template=answer_prompt_template)
#     if memory is None:
#         code_assistant = ConversationChain(
#             llm=llm,
#             prompt=answer_prompt
#         )
#     else:
#         code_assistant = ConversationChain(
#             llm=llm,
#             prompt=answer_prompt,
#             memory=memory
#         )
#
#     llm_based_tool = BaseChain(code_assistant, chain_type='ConversationChain')
#
#     return llm_based_tool
#
#
# def initialize_general_tools(tools_names_to_use: List[str], language_model=None, rag_chain_tool=None
#                              ) -> List:
#     """
#     Initialize tools based on the specified tool names and configurations.
#
#     Args:
#         tools_names_to_use: A list of tool names to initialize.
#         language_model: The language model chain.
#         rag_chain_tool: The RAG (Retrieval-Augmented Generation) chain tool.
#         llm_math_chain: The language model math chain.
#
#     Returns:
#         A list of initialized tools.
#     """
#     tools = list()
#
#     for tool_name in tools_names_to_use:
#
#         if tool_name == 'se_language_model' and rag_chain_tool is not None:
#             rag_bot = get_custom_tool(func=rag_chain_tool,
#                                       name="Stora Enso Large Language Model",
#                                       description="Use this tool to find internal legal information specific to Stora "
#                                                   "Enso, which may not be publicly available on the internet."
#
#                                       )
#             tools.append(rag_bot)
#         elif tool_name == 'duo_duck_search':
#             duo_duck_search = DuckDuckGoSearchRun()
#             duo_duck_search = get_custom_tool(func=duo_duck_search,
#                                               name="duo_duck_search",
#                                               description="useful for searching the internet for current or even"
#                                                           "future information"
#
#                                               )
#             tools.append(duo_duck_search)
#
#         # elif tool_name == 'math_tool':
#         #     problem_chain = LLMMathChain.from_llm(llm=language_model)
#         #
#         #     math_tool = get_custom_tool(func=problem_chain,
#         #                                 name="math_tool",
#         #                                 description="Useful for when you need to answer questions about math. "
#         #                                             "This tool is only for math questions and nothing else. "
#         #                                             "Only input math expressions."
#         #                                 )
#         #
#         #     tools.append(math_tool)
#
#         # elif tool_name == 'python_repl':
#         #     python_repl = get_custom_tool(func=PythonREPL(),
#         #                                   name="python_repl",
#         #                                   description="A Python shell. Use this to execute python "
#         #                                               "commands. Input"
#         #                                               "should be a valid python command. If you want to see the output "
#         #                                               "of a value, you should print it out with `print(...)`."
#         #                                   )
#         #     tools.append(python_repl)
#
#         # # TESTING
#         elif tool_name == 'python_repl':
#             python_repl = get_custom_tool(func=PythonAstREPLTool(),
#                                           name="python_repl",
#                                           description="A Python shell. Use this to execute python "
#                                                       "commands. Input"
#                                                       "should be a valid python command. If you want to see the output "
#                                                       "of a value, you should print it out with `print(...)`."
#                                           )
#             tools.append(python_repl)
#
#         elif tool_name == 'programmer' and language_model is not None:
#             code_assistant_func = initialize_llms_chain_as_tools(language_model,
#                                                                  prompts.agent_template_code_programmer)
#             code_assistant = get_custom_tool(func=code_assistant_func,
#                                              name="programmer",
#                                              description="An LLM and software engineer with expertise in tackling "
#                                                          "intricate Python code and refining software architecture using "
#                                                          "design pattern principles. Not useful for generating plots."
#                                              )
#             tools.append(code_assistant)
#
#         # elif tool_name == 'code_executer' and language_model is not None:
#         #     code_exec_func = load_llms_chain_as_tools(language_model,
#         #                                                    custom_prompts.agent_template_code_executer)
#         #     code_assistant = get_custom_tool(func=code_exec_func,
#         #                                      name="code_executer",
#         #                                      description="An LLM and software engineer with expertise in tackling "
#         #                                                  "intricate Python code and refining software architecture using "
#         #                                                  "design pattern principles. Not useful for generating plots."
#         #                                      )
#         #     tools.append(code_assistant)
#
#         elif tool_name == 'plot_displayer' and language_model is not None:
#             plot_displayer_func = initialize_llms_chain_as_tools(language_model,
#                                                                  custom_prompts.agent_template_plot_displayer)
#             code_assistant = get_custom_tool(func=plot_displayer_func,
#                                              name="plot_displayer",
#                                              description="Utilize this tool to request the generation of visualizations and plots."
#                                              )
#             tools.append(code_assistant)
#
#     return tools
#
#
# # -----
# # TEST
# # -----
#
# from typing import Optional
#
#
# def run_with_refinement(executor: AgentExecutor, query: str, insight: Optional[str] = None,
#                         intermediate_steps: Optional[str] = None) -> str:
#     """
#     Runs the AgentExecutor with custom logic to support both initial insight generation and
#     refinement based on the presence of an initial insight.
#
#     Args:
#         executor (AgentExecutor): The initialized agent executor.
#         query (str): The question or prompt to generate insights on.
#         insight (Optional[str]): An optional initial insight. If provided, the executor refines
#             this insight. Defaults to None.
#         intermediate_steps (Optional[str]): Additional intermediate steps or notes for refinement.
#
#     Returns:
#         str: The output from the agent, either an initial insight or a refined insight.
#     """
#     # Define the context for the first insight generation or the refinement
#     # context = f"{query}\n\nInitial Insight: {insight}" if insight else query
#     context = f"{query}\n\nInitial Insight: {insight}, Intermediate Steps: {intermediate_steps}" if insight else query  # TEST
#
#     # Run the executor with the provided context
#     response = executor({"input": context})
#
#     return response["output"]
#
